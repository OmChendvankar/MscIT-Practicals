#tidyverse for easy data manipulation and visualization
# caret for easily computing cross-validation methods

install.packages('tidyverse')
install.packages('caret')
library(tidyverse)
library(caret)
# Load the data
data("swiss")
# Inspect the data
sample_n(swiss, 3)
# Split the data into training and test set
set.seed(123)
training.samples<- swiss$Fertility %>%
  createDataPartition(p = 0.8, list = FALSE)
train.data<- swiss[training.samples, ]
test.data<- swiss[-training.samples, ]
# Build the model
model <- lm(Fertility ~., data = train.data)
# Make predictions and compute the R2, RMSE and MAE
predictions <- model %>% predict(test.data)
data.frame( R2 = R2(predictions, test.data$Fertility),
            RMSE = RMSE(predictions, test.data$Fertility),
            MAE = MAE(predictions, test.data$Fertility))



# Leave one out cross validation â€“ LOOCV
# Define training control
train.control<-trainControl(method="LOOCV")
# Train the model
model<-train(Fertility~., data=swiss, method="lm",trControl=train.control)
# Summarize the results
print(model)



# K-fold cross-validation
# Define training control
set.seed(123)
train.control<-trainControl(method="cv", number=10)
# Train the model
model<-train(Fertility~., data=swiss, method="lm",
             trControl=train.control)
# Summarize the results
print(model)



# Repeated K-fold cross-validation
# Define training control
set.seed(123)
train.control<-trainControl(method="repeatedcv", 
                            number=10, repeats=3)
# Train the model
model<-train(Fertility~., data=swiss, method="lm",
             trControl=train.control)
# Summarize the results
print(model)
